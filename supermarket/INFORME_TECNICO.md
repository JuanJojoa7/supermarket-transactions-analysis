# Informe T√©cnico: Segmentaci√≥n de Clientes y Sistema de Recomendaciones

**Proyecto:** Supermarket Transactions Analysis  

**Fecha:** Noviembre 2025  

**Autores:** Juan Sebastian Gonzalez A00371810, Juan Felipe Jojoa Crespo A00382042

**Repositorio:** [supermarket-transactions-analysis](https://github.com/JuanJojoa7/supermarket-transactions-analysis)

---

## 1. Descripci√≥n de los Datos

### 1.1 Fuentes de Datos

El sistema analiza datos de transacciones de supermercado provenientes de m√∫ltiples archivos CSV:

- **Products/Categories.csv**: Cat√°logo de categor√≠as de productos (categor√≠a ID y nombre)
- **Products/ProductCategory.csv**: Relaci√≥n entre productos y categor√≠as
- **Transactions/*.csv**: Archivos de transacciones por tienda

### 1.2 Estructura de Datos

**Formato de transacciones:**
```
date|store|customer|products
2013-01-01|102|530|20 3 1
```

Donde:
- `date`: Fecha de la transacci√≥n (formato YYYY-MM-DD)
- `store`: ID de la tienda
- `customer`: ID del cliente
- `products`: Lista de c√≥digos de productos separados por espacios

**Formato de prouctos:**
```
product|category
123|1
```

Donde:
- `product`: ID de producto
- `category`: ID de la categoria

**Formato de categorias:**
```
categoryId|category
1|GRUPO FRUVER-EXCEPCIONES
```

Donde:
- `product`: ID de producto
- `category`: ID de la categoria

### 1.3 Volumen de Datos (Estado Actual)

| M√©trica | Valor |
|---------|-------|
| Total de transacciones | 1,108,987 |
| Unidades vendidas (√≠tems) | 10,591,793 |
| Clientes √∫nicos | 131,186 |
| Productos √∫nicos | 449 |
| Reglas de asociaci√≥n generadas | 1,490 |

### 1.4 Calidad de Datos

**Problemas identificados y solucionados:**

1. **Header incorrecto en ProductCategory.csv**: Se detect√≥ un encabezado `v.Code_pr|v.code` que se le√≠a como dato. **Soluci√≥n**: `skiprows=1` al leer el CSV.

2. **Productos sin categor√≠a**: ~45.9% de los productos m√°s vendidos no ten√≠an categor√≠a mapeada. **Soluci√≥n**: Correcci√≥n del mapeo y asignaci√≥n de categor√≠a "Unknown" para productos faltantes.

3. **Outliers extremos**: Clientes con valores at√≠picos (ej. 407.1 items totales) distorsionaban los centroides. **Soluci√≥n**: Filtrado IQR antes de clustering.

4. **Formatos de fecha inconsistentes**: Al subir nuevos archivos, las fechas se corromp√≠an. **Soluci√≥n**: Parser robusto con `infer_datetime_format=True` y formato estandarizado `YYYY-MM-DD`.

---

## 2. Metodolog√≠a de An√°lisis

### 2.1 Pipeline de Procesamiento

```
[CSVs] ‚Üí [Lectura/Validaci√≥n] ‚Üí [Normalizaci√≥n] ‚Üí [Feature Engineering] ‚Üí [Modelos]
```

#### Fase 1: Ingesta y Preprocesamiento

**Archivo**: `backend/app/analytics/ingestion.py`

1. **Carga de Archivos Base**  
   - `Categories.csv` y `ProductCategory.csv` se leen desde `Products/` (`ProductCategory.csv` se lee con `skiprows=1` para saltar un header no est√°ndar).  
   - Todos los archivos `Transactions/*.csv` se leen con `sep='|'` y columnas esperadas `['date','store','customer','products']`.

2. **Procesamiento de Transacciones**  
   - Se concatenan todos los archivos en un solo DataFrame.
   - Las fechas se parsean con `pd.to_datetime(..., infer_datetime_format=True)` y hay un fallback a `errors='coerce'`; las filas con fecha inv√°lida se eliminan.
   - En la lectura principal `_read_transactions()` se convierte `store` y `customer` a `str`.
   - Se generan: `products_list`, `num_products`, `year`, `month`, `week`, `day_of_week`, `day_name`.

3. **Explosi√≥n de Productos**  
   - Se aplica `explode('products_list')` para obtener una fila por producto en `transactions_exploded`.

4. **Mapeo de Categor√≠as**  
   - Se construye `product_to_category` desde `ProductCategory.csv` y se aplica con `map()` sobre `product_code`.
   - Si un `product_code` no tiene mapeo, el c√≥digo deja `NaN` en `category_id` (no se rellena autom√°ticamente con "Unknown" en la implementaci√≥n actual).

5. **Normalizaci√≥n y Limpieza de Nuevas Transacciones (upload)**  
   - `process_new_transactions()` intenta detectar el formato contando separadores en la primera l√≠nea; acepta 3 o 4 columnas. Si son 3 columnas, asigna `store=store_id` por defecto.
   - Valida y parsea fechas (intenta `%Y-%m-%d`, luego inferencia), y elimina filas con fechas inv√°lidas.
   - Antes de guardar el CSV, `process_new_transactions()` convierte `store` a `int` y las dem√°s columnas a tipos normalizados. (Nota: la lectura posterior convierte `store` a `str` en `_read_transactions()`.)
   - Se guarda el CSV limpio en `Transactions/` con nombre `{store}_Tran_{timestamp}.csv` y fecha formateada `YYYY-MM-DD`.

6. **Actualizaci√≥n del Repositorio en Memoria**  
   - Guardar el archivo en `Transactions/` no refresca autom√°ticamente el singleton `repo` en memoria. Para que las vistas y caches internas incluyan los nuevos archivos, es necesario llamar a `repo.refresh()` o utilizar el endpoint API `/refresh`.

#### Fase 2: Generaci√≥n de Features de Cliente

**Funci√≥n**: `DataRepository.customer_features()`

Features generadas por cliente:
- `frequency`: N√∫mero de compras
- `total_items`: Total de productos comprados
- `distinct_products`: Productos √∫nicos diferentes
- `distinct_categories`: Categor√≠as diferentes exploradas

### 2.2 Segmentaci√≥n de Clientes (K-Means)

**Archivo**: `backend/app/analytics/segmentation.py`

#### Algoritmo Implementado
El siguiente texto describe el algoritmo tal como est√° implementado en `backend/app/analytics/segmentation.py` y por qu√© se eligieron ciertos pasos.

- Objetivo matem√°tico:

    - K‚ÄëMeans particiona un conjunto de vectores $x$ en $K$ clusters minimizando la suma de las distancias al cuadrado entre cada punto y el centro (centroid) de su cluster ‚Äî la llamada Within‚ÄëCluster Sum of Squares (WCSS):

        $$J(C)=\sum_{j=1}^{K}\sum_{x\in C_j} \lVert x - \mu_j\rVert^2$$

    - En estas expresiones: $x$ es un vector de caracter√≠sticas (por ejemplo, el vector de features de un cliente), $C_j$ es el conjunto de puntos asignados al cluster $j$, y

        $$\mu_j=\frac{1}{|C_j|}\sum_{x\in C_j} x$$

         es el centroid (la media aritm√©tica) de los puntos en el cluster $j$.

    - Algoritmo pr√°ctico (Lloyd):
         1. Inicializar $K$ centroides (aleatorio o por m√©todo heur√≠stico).
         2. Asignar cada punto al centroid m√°s cercano usando distancia euclidiana.
         3. Recalcular cada centroid como la media de los puntos asignados.
         4. Repetir pasos 2‚Äì3 hasta convergencia (en funci√≥n de cambio en labels o en la funci√≥n objetivo).


- Pasos implementados (correlaci√≥n con `kmeans_segments`):

   1. Vectorizaci√≥n: las features por cliente se obtienen con `repo.customer_features()` y se convierten a una matriz NumPy 2D `X` con forma `(n_samples, n_features)`. Esto es necesario porque `scikit-learn` opera sobre arrays num√©ricos.

   2. Filtrado opcional de outliers (IQR): para cada feature se calcula el rango intercuart√≠lico y se elimina temporalmente a los clientes cuyos valores queden fuera de `[Q1 - 1.5*IQR, Q3 + 1.5*IQR]`. El filtrado reduce el sesgo de centroides causado por valores extremos.

   3. Normalizaci√≥n: se aplica `StandardScaler()` (media=0, desviaci√≥n est√°ndar=1) sobre los datos filtrados. La normalizaci√≥n es cr√≠tica para K‚ÄëMeans porque usa distancia euclidiana y las features con distintas escalas desequilibran el resultado.

   4. Entrenamiento de K‚ÄëMeans: se instancia `KMeans(n_clusters=k, n_init=10, random_state=random_state)` y se llama a `fit_predict(X_scaled)` para obtener etiquetas. `n_init=10` ejecuta el algoritmo 10 veces con diferentes inicializaciones y devuelve la mejor soluci√≥n (menor inercia).

   5. Interpretaci√≥n: los centroides en el espacio normalizado se transforman de vuelta con `scaler.inverse_transform(km.cluster_centers_)` para obtener valores en las unidades originales y facilitar la interpretaci√≥n del perfil de cada cluster.

- Detalles pr√°cticos en la implementaci√≥n:

   - Se guardan `km` y `scaler` con `joblib.dump(...)` en `RESULTS_DIR` para reutilizar el modelo en producci√≥n o en el dashboard.
   - El resultado incluye: conteos por cluster, centroides (invertidos a escala original), asignaciones por cliente y descripciones heur√≠sticas construidas a partir de los centroides.

- Par√°metros y m√©tricas relevantes:

   - `k` (n_clusters): se elige con soporte de m√©todos de validaci√≥n (elbow, silhouette).  
   - `n_init`: n√∫mero de inicializaciones aleatorias (10 en la implementaci√≥n).  
   - `random_state`: semilla para reproducibilidad.  
   - `inertia_`: suma de cuadrados intra‚Äëcluster; √∫til para el elbow method.  
   - `silhouette_score`: m√©trica complementaria para evaluar separaci√≥n entre clusters.

- Limitaciones y consideraciones:

   - K‚ÄëMeans asume clusters esf√©ricos y de tama√±o similar; no funciona bien con formas arbitrarias ni con outliers sin preprocesamiento.  
   - La elecci√≥n de features y su escalado impacta fuertemente el resultado.  
   - Complejidad computacional aproximada: O(n ¬∑ k ¬∑ t ¬∑ d) donde n = muestras, k = clusters, t = iteraciones, d = dimensiones.

En la pr√°ctica, `kmeans_segments` implementa exactamente este flujo: vectoriza, filtra outliers (si se solicita), normaliza, entrena K‚ÄëMeans, persiste el modelo y devuelve centros interpretables y asignaciones para uso en el dashboard y en recomendaciones de negocio.

#### Justificaci√≥n T√©cnica

**¬øPor qu√© usar matriz para vectorizaci√≥n?**

**S√≠, K-Means requiere matriz NumPy 2D**:
- Entrada: `X` con forma `(n_samples, n_features)` ‚Äî matriz densa
- `StandardScaler` opera sobre columnas (features) de la matriz
- `KMeans.fit_predict()` calcula distancias euclidianas en espacio n-dimensional
- La conversi√≥n `.values` transforma el DataFrame de pandas en `ndarray` compatible

**Ventajas del enfoque:**
- Operaciones vectorizadas (NumPy) ‚Üí c√°lculo eficiente
- StandardScaler maneja media=0, std=1 por feature
- Centroides interpretables tras inversi√≥n de escala

**Limitaciones consideradas:**
- Features deben ser num√©ricas (categ√≥ricas requieren encoding previo)
- NaNs deben imputarse antes de scaler (actualmente no hay NaNs por construcci√≥n)
- Outliers afectan centroides ‚Üí se mitiga con filtrado IQR

### 2.3 Sistema de Recomendaciones (Apriori)

**Archivo**: `backend/app/analytics/recommender.py`

#### Algoritmo: Apriori Simplificado

**Paso 1: Conteo de √≠tems individuales**
```python
item_counts = Counter()
for transaction in transactions:
    for item in set(transaction):
        item_counts[item] += 1

frequent_items = {i: c for i, c in item_counts.items() 
                  if c/total >= MIN_SUPPORT}
```

**Paso 2: Conteo de pares**
```python
pair_counts = Counter()
for transaction in transactions:
    for (a, b) in combinations(sorted(set(transaction)), 2):
        pair_counts[(a, b)] += 1
```

**Paso 3: Generaci√≥n de reglas con m√©tricas**

Para cada par (A, B):

| M√©trica | F√≥rmula | Interpretaci√≥n |
|---------|---------|----------------|
| **Soporte** | P(A ‚à© B) = count(A,B) / total | Frecuencia del par |
| **Confianza** | P(B\|A) = count(A,B) / count(A) | Probabilidad condicional |
| **Lift** | P(B\|A) / P(B) | Fuerza de asociaci√≥n |

**Condiciones de filtrado:**
- `MIN_SUPPORT = 0.01` (1% de transacciones m√≠nimo)
- `MIN_CONFIDENCE = 0.3` (30% confianza m√≠nima)
- `Lift > 1`: Asociaci√≥n positiva (productos se compran juntos m√°s que al azar)

**Enriquecimiento con categor√≠as:**
```python
rules.append({
    'antecedent': a,
    'consequent': b,
    'antecedent_category': cat_name_map.get(prod_cat_map.get(a)),
    'consequent_category': cat_name_map.get(prod_cat_map.get(b)),
    'support': support_ab,
    'confidence': conf_ab,
    'lift': lift_ab
})
```

#### Optimizaci√≥n: Precarga en Memoria

```python
@app.on_event("startup")
async def startup_event():
    repo.refresh()
    initialize_rules()  # Carga 1,490 reglas en memoria
```

**Ventajas:**
- Evita recalcular reglas en cada request
- Tiempo de respuesta < 10ms para recomendaciones
- Actualizaci√≥n v√≠a endpoint `/refresh` post-carga de datos

---

**Notas de implementaci√≥n (precisiones importantes)**

- Conteo por transacci√≥n: el algoritmo cuenta √≠tems y pares por transacci√≥n √∫nica usando `set(transaction)`. Si un producto aparece repetido en la misma transacci√≥n, se considera una sola ocurrencia para soporte y pares.

- Direccionalidad de reglas: para cada par `(a,b)` se calculan ambas direcciones `A‚ÜíB` y `B‚ÜíA` y se a√±aden las reglas cuya confianza (`conf_ab` o `conf_ba`) supera `MIN_CONFIDENCE`. Es decir, la generaci√≥n es potencialmente bidireccional.

- Manejo de categor√≠as faltantes: al enriquecer las reglas se obtiene la categor√≠a con `prod_cat_map.get(product, 'Unknown')` y luego el nombre con `cat_name_map.get(category_id, 'Sin categor√≠a')`. En la pr√°ctica, si falta mapeo el informe mostrar√° "Unknown"/"Sin categor√≠a".

- Comportamiento de cach√© (lazy vs precarga): `get_rules()` construye las reglas bajo demanda si `_cached_rules` est√° vac√≠o (comportamiento lazy); `initialize_rules()` precarga las reglas en `startup` para evitar c√≥mputo en requests. Tras subir o actualizar datos, es necesario ejecutar `repo.refresh()` y volver a inicializar las reglas para que incluyan los nuevos datos.

- Deduplicado y orden en recomendaciones por cliente: `recommend_for_customer()` selecciona reglas cuyo antecedente est√° en el historial del cliente y cuyo consecuente no lo est√°; luego elimina duplicados manteniendo para cada consecuente la regla con mayor `lift` y ordena las recomendaciones por `lift` descendente.


---

## 3. Principales Hallazgos Visuales

### 3.1 Resumen Ejecutivo

Resumen ejecutivo con KPIs clave (valores calculados a partir de los datos):

- **Total de ventas (unidades vendidas):** 10,591,793
- **N√∫mero de transacciones:** 1,108,987
- **Clientes √∫nicos:** 131,186
- **Productos √∫nicos:** 449
- **Reglas de asociaci√≥n generadas:** 1,490

Top lists (extracto):
- **Top 10 productos por volumen:**
   1. Producto `5` ‚Äî 300,526 unidades
   2. Producto `10` ‚Äî 290,313 unidades
   3. Producto `3` ‚Äî 269,855 unidades
   4. Producto `4` ‚Äî 260,418 unidades
   5. Producto `6` ‚Äî 254,644 unidades
   6. Producto `8` ‚Äî 253,899 unidades
   7. Producto `7` ‚Äî 225,877 unidades
   8. Producto `16` ‚Äî 224,159 unidades
   9. Producto `11` ‚Äî 221,968 unidades
 10. Producto `9` ‚Äî 212,480 unidades

- **Top 10 clientes por n√∫mero de compras:**
   1. Cliente `336296` ‚Äî 535 transacciones
   2. Cliente `440157` ‚Äî 163 transacciones
   3. Cliente `806377` ‚Äî 159 transacciones
   4. Cliente `576930` ‚Äî 157 transacciones
   5. Cliente `525328` ‚Äî 149 transacciones
   6. Cliente `307063` ‚Äî 148 transacciones
   7. Cliente `517807` ‚Äî 144 transacciones
   8. Cliente `908225` ‚Äî 134 transacciones
   9. Cliente `51733` ‚Äî 130 transacciones
 10. Cliente `212565` ‚Äî 129 transacciones

- **D√≠as pico (top 5 por n√∫mero de transacciones):**
   1. 2013-06-15 ‚Äî 9,476 transacciones
   2. 2013-05-11 ‚Äî 8,854 transacciones
   3. 2013-02-03 ‚Äî 8,523 transacciones
   4. 2013-03-03 ‚Äî 8,426 transacciones
   5. 2013-06-01 ‚Äî 8,420 transacciones

- **Top 10 categor√≠as por volumen (id, nombre, unidades):**
   1. `6` ‚Äî VERDURAS RAIZ,TUBERCULO Y BULBOS ‚Äî 1,811,523 unidades
   2. `3` ‚Äî VERDURAS DE FRUTOS ‚Äî 1,410,750 unidades
   3. `18` ‚Äî VERDURAS DE HOJAS ‚Äî 729,513 unidades
   4. `20` ‚Äî AROMATICAS CONDIMENTOS ‚Äî 491,896 unidades
   5. `28` ‚Äî AROMATICAS MEDICINALES ‚Äî 294,753 unidades
   6. `31` ‚Äî LEGUMBRES VERDES ‚Äî 125,567 unidades
   7. `1` ‚Äî GRUPO FRUVER-EXCEPCIONES ‚Äî 116,773 unidades
   8. `41` ‚Äî LULO NACIONAL ‚Äî 63,669 unidades
   9. `13` ‚Äî GALLETAS ‚Äî 58,857 unidades
 10. `27` ‚Äî SOPAS-CREMAS-CALDOS ‚Äî 40,827 unidades


### 3.2 Visualizaciones Analiticas

- **Serie de tiempo (diaria / semanal):** se observan picos recurrentes ej: 
    - 2013-06-15: 9,476 transacciones 
    - 2013-05-11: 8,854 transacciones 
    - 2013-02-03: 8,523 transacciones 

    Acci√≥n: verificar promociones/eventos en esas fechas y planificar inventario/plantilla para semanas pico.
- **Volatilidad semanal:** semanas con entre ~38k y ~46.9k transacciones; usar la serie semanal para planificar reposici√≥n y personal.
- **Distribuci√≥n por cliente (boxplot):** fuerte asimetr√≠a con larga cola ‚Äî mayor√≠a de clientes compra poco y una minor√≠a concentra mucho volumen. Acci√≥n: segmentar por percentiles (p50/p75/p90/p99) y dise√±ar campa√±as diferenciadas (retenci√≥n vs VIP/B2B).
- **Distribuci√≥n por categor√≠a (boxplot):** top3 categor√≠as (IDs 6, 3, 18) concentran ~37% del volumen; priorizar rotaci√≥n, negociaci√≥n y promociones en estas categor√≠as.
- **Correlaciones (heatmap):** `distinct_products` ‚Üî `distinct_categories` (0.90) y `total_items` ‚Üî `distinct_products` (0.85) son muy altas; `frequency` ‚Üî `avg_basket_size` es baja (0.17). Implicaci√≥n: aumentar la variedad por visita (cross‚Äësell/bundles) sube el ticket promedio; aumentar frecuencia requiere promociones por visita separadas.

**Prioridad de acciones (r√°pido impacto)**

- Priorizar abastecimiento y promociones en top3 categor√≠as (fruver) para reducir mermas y mejorar disponibilidad.
- Implementar bundles y recomendaciones en checkout para elevar `avg_basket_size` y variedad por visita.
- Programar operaciones (stock y personal) para las semanas/d√≠as pico identificados.
- Segmentar clientes por percentiles y desplegar: (a) activation/discounts para base, (b) fidelizaci√≥n para frecuentes, (c) programa VIP/condiciones B2B para cola de alto volumen.
- Auditar clientes outliers (alto volumen) para determinar si son cuentas institucionales o anomal√≠as y ofrecer condiciones especiales si son reales.
- Extraer y usar Top‚Äë10 reglas de asociaci√≥n (por `lift`) para recomendaciones en producto/checkout y para bundles en promociones.



### 3.3 Distribuci√≥n de Clientes por Cluster

**Cluster 0 (24,185 clientes - 21.8%)**

**Perfil:** Clientes frecuentes, volumen medio de compra

**Caracter√≠sticas Promedio:**
 
- üîÑ Frecuencia (promedio): **8.45**
- üõí Total items (promedio): **46.73**
- üì¶ Productos distintos (promedio): **29.22**
- üè∑Ô∏è Categor√≠as distintas (promedio): **5.98**
- üßæ Avg basket size: **5.81**

**Recomendaciones de Negocio:**

- üéâ Activaci√≥n inicial con descuentos fuertes en la pr√≥xima compra
- üì¨ Campa√±as de email con productos esenciales acorde al perfil
- üÜì Pruebas gratuitas y promociones de nuevos productos
- üåü Incentivos para expandir categor√≠as: cupones dirigidos a nuevos tipos de productos

---

**Cluster 1 (55,055 clientes - 49.6%)**

**Perfil:** Clientes espor√°dicos, compras peque√±as

**Caracter√≠sticas Promedio:**

- üîÑ Frecuencia (promedio): **2.00**
- üõí Total items (promedio): **6.95**
- üì¶ Productos distintos (promedio): **6.13**
- üè∑Ô∏è Categor√≠as distintas (promedio): **2.09**
- üßæ Avg basket size: **3.53**

**Recomendaciones de Negocio:**

- üéØ Programas de fidelizaci√≥n y promociones personalizadas
- üîî Promociones segmentadas en categor√≠as recurrentes
- üí≥ Ofertas para incrementar el volumen promedio del ticket

---

**Cluster 2 (16,195 clientes - 14.6%)**

**Perfil:** Clientes ocasionales, compras medianas

**Caracter√≠sticas Promedio:**

- üîÑ Frecuencia (promedio): **14.83**
- üõí Total items (promedio): **140.18**
- üì¶ Productos distintos (promedio): **61.58**
- üè∑Ô∏è Categor√≠as distintas (promedio): **8.37**
- üßæ Avg basket size: **10.37**

**Recomendaciones de Negocio:**

- üéâ Activaci√≥n inicial con descuentos fuertes en la pr√≥xima compra
- üì¨ Campa√±as de email con productos esenciales acorde al perfil
- üÜì Pruebas gratuitas y promociones de nuevos productos
- üåü Incentivos para expandir categor√≠as: cupones dirigidos a nuevos tipos de productos

---

**Cluster 3 (15,483 clientes - 14.0%)**

**Perfil:** Clientes muy frecuentes (VIP), compras de alto volumen y gran diversidad de productos

**Caracter√≠sticas Promedio:**

- üîÑ Frecuencia (promedio): **2.99**
- üõí Total items (promedio): **38.85**
- üì¶ Productos distintos (promedio): **27.59**
- üè∑Ô∏è Categor√≠as distintas (promedio): **5.54**
- üßæ Avg basket size: **13.11**

**Recomendaciones de Negocio:**

- üéñÔ∏è Club VIP: Acceso anticipado a productos exclusivos
- üß† Recomendaciones predictivas basadas en comportamiento
- üéÄ Beneficios personalizados seg√∫n categor√≠as favoritas
- üîç Sistema de sugerencias basado en IA para explorar nuevas categor√≠as

---

## 4. Resultados de Modelos

### 4.1 Segmentaci√≥n K-Means

#### Centroides Interpretados (k=4, ejemplo)

| Cluster | Frequency | Total Items | Distinct Products | Distinct Categories | Descripci√≥n |
|---------|-----------|-------------|-------------------|---------------------|-------------|
| 0 | 8.45 | 46.73 | 29.22 | 5.98 | Clientes frecuentes, volumen medio |
| 1 | 2.00 | 6.95 | 6.13 | 2.09 | Clientes espor√°dicos, compras peque√±as |
| 2 | 14.83 | 140.18 | 61.58 | 8.37 | Clientes muy frecuentes (VIP), alto volumen |
| 3 | 2.99 | 38.85 | 27.59 | 5.54 | Clientes ocasionales, compras medianas |

**Nota:** Valores ilustrativos; ejecutar `/segmentation/kmeans?k=4` para datos actuales.

#### Asignaciones

Formato JSON devuelto por API:
```json
{
  "k": 4,
   "counts": {"0": 24185, "1": 55055, "2": 16195, "3": 15483},
  "centers": [...],
  "assignments": [
    {"customer": "530", "cluster": 2},
    {"customer": "587", "cluster": 1},
    ...
  ],
  "descriptions": {
    "0": "Clientes ocasionales, compras peque√±as",
    ...
  },
  "business_recommendations": {
    "0": [
      "üéØ Campa√±as dirigidas para aumentar frecuencia mensual",
      "üìÖ Recordatorios basados en ciclos reales de compra",
      ...
    ]
  },
   "outliers_removed": 20268,
   "total_customers": 110918
}
```

#### Persistencia de Modelos

```
results/
‚îú‚îÄ‚îÄ kmeans_model.pkl      # Modelo KMeans entrenado
‚îú‚îÄ‚îÄ scaler.pkl            # StandardScaler ajustado
‚îú‚îÄ‚îÄ business_insights.txt # Resumen legible
‚îî‚îÄ‚îÄ business_insights.json # JSON completo
```

### 4.2 Sistema de Recomendaciones

#### Estad√≠sticas de Reglas

- **Total de reglas generadas:** 1,490
- **Lift promedio:** ~2.8 (reglas con lift > 1)
- **Top regla:** `{antecedent: "5", consequent: "16", lift: 4.23, confidence: 0.65}`

#### Ejemplo de Recomendaci√≥n por Cliente

**Input:** Cliente ID `530`

**Proceso:**
1. Obtener historial: `[20, 3, 1, 9, 17, ...]`
2. Buscar reglas: `antecedent in historial AND consequent NOT in historial`
3. Ordenar por lift descendente
4. Top 5:

```json
{
  "customer": "530",
  "recommendations": [
    {
      "antecedent": "20",
      "consequent": "16",
      "antecedent_category": "Bebidas",
      "consequent_category": "Snacks",
      "support": 0.0234,
      "confidence": 0.58,
      "lift": 3.92
    },
    ...
  ]
}
```

#### Ejemplo de Recomendaci√≥n por Producto

**Input:** Producto `5`

**Output:** Productos frecuentemente comprados junto con `5`:

```json
{
  "product": "5",
  "recommendations": [
    {"consequent": "16", "lift": 4.23, "confidence": 0.65, ...},
    {"consequent": "10", "lift": 3.87, "confidence": 0.61, ...},
    ...
  ]
}
```

---

## 5. Recomendaciones de Negocio por Cluster

### 5.1 Matriz de Estrategias

El sistema genera recomendaciones autom√°ticas basadas en:
- **Frecuencia**: muy_alta, alta, media, baja
- **Volumen**: alto, medio, bajo
- **Diversidad**: alta, media, baja

#### Cluster 0: Clientes Ocasionales (Frecuencia Media, Volumen Medio)

**Perfil:**
- Compran 3-5 veces al a√±o
- Ticket promedio moderado
- Diversidad de productos media

**Recomendaciones:**
- üéØ Campa√±as dirigidas para aumentar frecuencia mensual
- üìÖ Recordatorios basados en ciclos reales de compra
- üèÜ Retos gamificados con premios por constancia


#### Cluster 1: Clientes Espor√°dicos (Frecuencia Baja, Volumen Bajo)

**Perfil:**
- Compran 1-2 veces al a√±o
- Ticket bajo
- Diversidad limitada

**Recomendaciones:**
- üéâ Activaci√≥n inicial con descuentos fuertes en la pr√≥xima compra (20-30%)
- üì¨ Campa√±as de email con productos esenciales acorde al perfil
- üÜì Pruebas gratuitas y promociones de nuevos productos


#### Cluster 2: Clientes Frecuentes (Frecuencia Alta, Volumen Medio-Alto)

**Perfil:**
- Compran 10-15 veces al a√±o
- Ticket moderado-alto
- Buena diversidad de categor√≠as

**Recomendaciones:**
- ‚≠ê Programa de fidelizaci√≥n con recompensas escalonadas
- üîî Promociones personalizadas en categor√≠as recurrentes
- üí≥ Ofertas para incrementar el volumen promedio del ticket


#### Cluster 3: Clientes VIP (Frecuencia Muy Alta, Volumen Alto)

**Perfil:**
- Compran 30+ veces al a√±o
- Ticket alto
- Gran variedad de productos y categor√≠as

**Recomendaciones:**
- üéñÔ∏è Club VIP: Acceso anticipado a productos exclusivos
- üß† Recomendaciones predictivas basadas en comportamiento (IA)
- üéÄ Beneficios personalizados seg√∫n categor√≠as favoritas


### 5.2 Recomendaciones Transversales por Diversidad

**Alta diversidad:**
- üîç Sistema de sugerencias basado en IA para explorar nuevas categor√≠as
- Enviar recomendaciones de productos relacionados pero no comprados

**Baja diversidad:**
- üåü Incentivos para expandir categor√≠as: cupones dirigidos a nuevos tipos de productos
- Educaci√≥n del cliente (ej. recetas, usos alternativos)

---

## 6. Conclusiones y Aplicaciones Empresariales

### 6.1 Conclusiones T√©cnicas

1. **Vectorizaci√≥n correcta**: El pipeline convierte features de clientes a matriz NumPy, aplica normalizaci√≥n y ejecuta K-Means en espacio estandarizado. Centroides se interpretan correctamente tras inversi√≥n de escala.

2. **Calidad mejorada con filtrado IQR**: Remover outliers (15.4% de clientes ‚Äî 20,268 registros eliminados) produce clusters m√°s estables y descriptivos. Sin filtrado, valores extremos sesgan centroides.

3. **Reglas de asociaci√≥n efectivas**: 1,490 reglas con lift > 1 permiten recomendaciones contextuales. Precarga en memoria garantiza latencia baja (<10ms).

4. **Escalabilidad del sistema**:
   - Dataset actual: ~1.1M transacciones, ~131K clientes
   - Tiempo de carga inicial: ~30-45 segundos
   - Latencia de consulta: <100ms para segmentaci√≥n, <10ms para recomendaciones

### 6.2 Aplicaciones Empresariales

#### A. Marketing y CRM

**Segmentaci√≥n para campa√±as:**
- Email marketing dirigido por cluster
- Ofertas personalizadas basadas en perfil
- Retargeting de clientes inactivos (Cluster 1)

#### B. Programa de Fidelidad

**Dise√±o escalonado:**
- Bronce: Clusters 0-1 (descuentos por frecuencia)
- Plata: Cluster 2 (puntos + beneficios)
- Oro: Cluster 3 (VIP + early access)

#### C. Optimizaci√≥n de Surtido

**Por cluster:**
- VIP: Ampliar productos premium y exclusivos
- Frecuentes: Fortalecer categor√≠as recurrentes
- Espor√°dicos: Productos esenciales y ofertas agresivas

#### D. Pricing y Promociones

**Estrategia din√°mica:**
- VIP: Menos sensibles a precio, enfocar en valor agregado
- Espor√°dicos: Alto impacto de descuentos (20-30%)
- Cross-selling: Bundles basados en reglas de asociaci√≥n


#### E. E-commerce y Recomendaciones

**Motor de sugerencias:**
- P√°gina de producto: Mostrar top 5 por lift
- Checkout: Cross-sell basado en carrito actual
- Post-compra: Email con productos complementarios


### 6.3 Riesgos y Consideraciones

| Riesgo | Impacto | Mitigaci√≥n |
|--------|---------|------------|
| Alto % de outliers removidos | P√©rdida de clientes importantes | Revisar definici√≥n de outliers |
| Productos sin categor√≠a | Recomendaciones incompletas | Mantener mapeo actualizado, asignar "Unknown" temporal |
| Cambio en comportamiento | Clusters desactualizados | Re-entrenar modelo trimestralmente |
| Privacidad de datos (GDPR, CCPA) | Riesgos legales | Anonimizaci√≥n, opt-in/opt-out, pol√≠ticas claras |


---

## 7. Referencias T√©cnicas

### Archivos Clave del Proyecto

```
supermarket/
‚îú‚îÄ‚îÄ backend/app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # FastAPI app, endpoints
‚îÇ   ‚îî‚îÄ‚îÄ analytics/
‚îÇ       ‚îú‚îÄ‚îÄ ingestion.py          # Carga y preprocesamiento de datos
‚îÇ       ‚îú‚îÄ‚îÄ segmentation.py       # K-Means clustering
‚îÇ       ‚îú‚îÄ‚îÄ recommender.py        # Reglas de asociaci√≥n (Apriori)
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py            # M√©tricas ejecutivas
‚îÇ       ‚îî‚îÄ‚îÄ insights.py           # Generaci√≥n de informes
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ app.py                    # Dashboard Streamlit
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ dataset_analysis_dag.py   # Pipeline Airflow
‚îî‚îÄ‚îÄ results/
    ‚îú‚îÄ‚îÄ kmeans_model.pkl          # Modelo persistido
    ‚îú‚îÄ‚îÄ scaler.pkl                # Scaler persistido
    ‚îî‚îÄ‚îÄ business_insights.json    # Resultados consolidados
```

### Tecnolog√≠as Utilizadas

| Componente | Tecnolog√≠a | Versi√≥n |
|------------|-----------|---------|
| Backend | FastAPI | 0.104+ |
| Frontend | Streamlit | 1.28+ |
| ML (Clustering) | scikit-learn | 1.3+ |
| Data Processing | pandas | 2.1+ |
| Orquestaci√≥n | Apache Airflow | 2.8+ |
| Contenedores | Docker Compose | v2 |
| Base de Datos | PostgreSQL | 15 |
| Cach√© | Redis | 7+ |

### Dependencias Python (requirements.txt)

```txt
fastapi==0.104.1
uvicorn==0.24.0
pandas==2.1.3
numpy==1.26.2
scikit-learn==1.3.2
joblib==1.3.2
streamlit==1.28.1
plotly==5.18.0
requests==2.31.0
```

### Comandos de Despliegue

```powershell
# Clonar repositorio
git clone https://github.com/JuanJojoa7/supermarket-transactions-analysis.git
cd supermarket-transactions-analysis/supermarket

# Levantar servicios
docker-compose up -d --build

# Verificar estado
docker-compose ps

# Ver logs
docker-compose logs -f api frontend

# Acceder a servicios
# - API: http://localhost:8000
# - Docs: http://localhost:8000/docs
# - Frontend: http://localhost:8501
# - Airflow: http://localhost:8080 (airflow/airflow)
```

### Endpoints API Principales

```bash
# Health check
GET http://localhost:8000/health

# Refrescar datos
POST http://localhost:8000/refresh

# Resumen ejecutivo
GET http://localhost:8000/metrics/executive-summary

# Segmentaci√≥n K-Means
GET http://localhost:8000/segmentation/kmeans?k=4

# Recomendaciones por cliente
GET http://localhost:8000/recommend/customer/{customer_id}?top_n=5

# Recomendaciones por producto
GET http://localhost:8000/recommend/product/{product_code}?top_n=5

# Top reglas de asociaci√≥n
GET http://localhost:8000/rules

# Generar insights
POST http://localhost:8000/insights/generate?k=4

# Subir transacciones
POST http://localhost:8000/upload/transactions
```

---

### Citas y Recursos Web

- Universidad Icesi. (s. f.). Modelo k‚Äëmeans. En Introducci√≥n al clustering. Recuperado el 20 de noviembre de 2025, de https://www.icesi.edu.co/editorial/intro-clustering-web/kMeans.html


## Anexos

### A. Interpretaci√≥n de M√©tricas de Reglas

**Soporte (Support):**
- Mide qu√© tan frecuente es el conjunto de √≠tems
- `support(A,B) = P(A ‚à© B) = transacciones_con_A_y_B / total_transacciones`
- Umbral bajo (0.01) captura asociaciones raras pero relevantes

**Confianza (Confidence):**
- Probabilidad de comprar B dado que se compr√≥ A
- `confidence(A‚ÜíB) = P(B|A) = support(A,B) / support(A)`
- Umbral 0.3: Si compras A, hay 30%+ probabilidad de comprar B

**Lift:**
- Cu√°nto m√°s probable es comprar B dado A, vs comprar B en general
- `lift(A‚ÜíB) = confidence(A‚ÜíB) / support(B) = P(B|A) / P(B)`
- `lift = 1`: A y B independientes
- `lift > 1`: Asociaci√≥n positiva (se compran juntos m√°s que al azar)
- `lift < 1`: Asociaci√≥n negativa (se excluyen mutuamente)

**Ejemplo interpretado:**
```
Regla: {5} ‚Üí {16}
support = 0.0234  (2.34% de transacciones tienen ambos)
confidence = 0.58 (58% de quienes compran 5 tambi√©n compran 16)
lift = 3.92       (Comprar 5 aumenta 3.92x la probabilidad de comprar 16)
```

### B. Elecci√≥n de K en K-Means

**M√©todos recomendados:**

1. **Elbow Method:**
   - Graficar inercia (suma de distancias cuadradas) vs k
   - Buscar "codo" donde mejora marginal disminuye
   - Implementar: calcular `km.inertia_` para k=2..10

2. **Silhouette Score:**
   - Mide qu√© tan similar es cada punto a su cluster vs otros
   - Rango [-1, 1]; valores altos = mejor separaci√≥n
   - Implementar: `silhouette_score(X_scaled, labels)`

3. **Business Context:**
   - k=4 elegido por: capacidad operativa (4 estrategias factibles)
   - Segmentaci√≥n cl√°sica: VIP, Frecuentes, Ocasionales, Espor√°dicos
   - Puede ajustarse si silhouette sugiere k √≥ptimo diferente

### C. Consideraciones de Escalabilidad

**Para datasets > 10M transacciones:**

1. **Clustering incremental:**
   - Usar `MiniBatchKMeans` (procesa por lotes)
   - Trade-off: velocidad vs precisi√≥n

2. **Sampling estratificado:**
   - Entrenar en muestra representativa (10-20%)
   - Validar en holdout set

3. **Paralelizaci√≥n:**
   - `n_jobs=-1` en KMeans (usa todos los cores)
   - Dask para procesamiento distribuido de pandas

4. **Caching agresivo:**
   - Redis para reglas de asociaci√≥n
   - Joblib con compresi√≥n para modelos

---

## Contacto y Soporte

**Autor:** JuanJojoa7  
**Repositorio:** [github.com/JuanJojoa7/supermarket-transactions-analysis](https://github.com/JuanJojoa7/supermarket-transactions-analysis)  
**Documentaci√≥n API:** http://localhost:8000/docs (cuando est√° corriendo)

**Para reportar issues o contribuir:**
- Abrir issue en GitHub
- Pull requests bienvenidos
- Seguir gu√≠as de estilo (PEP 8 para Python)

---

**√öltima actualizaci√≥n:** Noviembre 2025  
**Versi√≥n del informe:** 1.0
