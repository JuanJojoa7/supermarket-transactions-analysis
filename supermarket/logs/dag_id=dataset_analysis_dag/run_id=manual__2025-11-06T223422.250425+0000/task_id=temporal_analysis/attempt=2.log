[2025-11-06T22:43:40.639+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dataset_analysis_dag.temporal_analysis manual__2025-11-06T22:34:22.250425+00:00 [queued]>
[2025-11-06T22:43:40.669+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dataset_analysis_dag.temporal_analysis manual__2025-11-06T22:34:22.250425+00:00 [queued]>
[2025-11-06T22:43:40.671+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 4
[2025-11-06T22:43:40.711+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): temporal_analysis> on 2025-11-06 22:34:22.250425+00:00
[2025-11-06T22:43:40.727+0000] {standard_task_runner.py:60} INFO - Started process 570 to run task
[2025-11-06T22:43:40.736+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'dataset_analysis_dag', 'temporal_analysis', 'manual__2025-11-06T22:34:22.250425+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/dataset_analysis_dag.py', '--cfg-path', '/tmp/tmpmygtl01q']
[2025-11-06T22:43:40.739+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask temporal_analysis
[2025-11-06T22:43:40.889+0000] {task_command.py:423} INFO - Running <TaskInstance: dataset_analysis_dag.temporal_analysis manual__2025-11-06T22:34:22.250425+00:00 [running]> on host d6185d1f83fb
[2025-11-06T22:43:41.135+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Marin_Botina' AIRFLOW_CTX_DAG_ID='dataset_analysis_dag' AIRFLOW_CTX_TASK_ID='temporal_analysis' AIRFLOW_CTX_EXECUTION_DATE='2025-11-06T22:34:22.250425+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-06T22:34:22.250425+00:00'
[2025-11-06T22:46:23.824+0000] {logging_mixin.py:188} INFO - 
=== ANÁLISIS TEMPORAL ===
[2025-11-06T22:46:23.826+0000] {logging_mixin.py:188} INFO - 
Estadísticas diarias:
[2025-11-06T22:46:23.827+0000] {logging_mixin.py:188} INFO - Media de transacciones diarias: 6127.00
[2025-11-06T22:46:23.829+0000] {logging_mixin.py:188} INFO - Máximo de transacciones en un día: 9476
[2025-11-06T22:46:23.832+0000] {logging_mixin.py:188} INFO - Mínimo de transacciones en un día: 2860
[2025-11-06T22:46:23.834+0000] {logging_mixin.py:188} INFO - 
Ventas por día de la semana:
[2025-11-06T22:46:23.836+0000] {logging_mixin.py:188} INFO - Monday: 142445 transacciones, 1301747 productos
[2025-11-06T22:46:23.838+0000] {logging_mixin.py:188} INFO - Tuesday: 150739 transacciones, 1606571 productos
[2025-11-06T22:46:23.840+0000] {logging_mixin.py:188} INFO - Wednesday: 137245 transacciones, 1175689 productos
[2025-11-06T22:46:23.841+0000] {logging_mixin.py:188} INFO - Thursday: 158766 transacciones, 1506585 productos
[2025-11-06T22:46:23.843+0000] {logging_mixin.py:188} INFO - Friday: 139371 transacciones, 1213602 productos
[2025-11-06T22:46:23.844+0000] {logging_mixin.py:188} INFO - Saturday: 189015 transacciones, 1860948 productos
[2025-11-06T22:46:23.846+0000] {logging_mixin.py:188} INFO - Sunday: 191406 transacciones, 1926651 productos
[2025-11-06T22:46:23.914+0000] {xcom.py:664} ERROR - keys must be str, int, float, bool or None, not Timestamp. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2025-11-06T22:46:23.928+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dataset_analysis_dag.py", line 268, in temporal_analysis
    context['ti'].xcom_push(key='temporal_results', value=temporal_results)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2980, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 247, in set
    value = cls.serialize_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 662, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/json.py", line 104, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
TypeError: keys must be str, int, float, bool or None, not Timestamp
[2025-11-06T22:46:24.039+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=dataset_analysis_dag, task_id=temporal_analysis, execution_date=20251106T223422, start_date=20251106T224340, end_date=20251106T224624
[2025-11-06T22:46:24.121+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task temporal_analysis (keys must be str, int, float, bool or None, not Timestamp; 570)
[2025-11-06T22:46:24.315+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-11-06T22:46:24.436+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
